{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import re\n",
    "import yaml\n",
    "import math\n",
    "import warnings\n",
    "from openai import OpenAI\n",
    "from groq import Groq\n",
    "from tqdm import tqdm\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = os.path.join(os.getcwd(), \"config.yaml\")\n",
    "\n",
    "with open(config_path, \"r\") as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "openai_api_key = config[\"openai\"][\"api_key\"]\n",
    "openai_organization = config[\"openai\"][\"organization\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_openai = OpenAI(api_key=openai_api_key, organization=openai_organization)\n",
    "\n",
    "def get_response_openai(model, prompt, temperature=0.0, top_p=0.95, max_tokens=2048):\n",
    "    completion = client_openai.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=temperature,\n",
    "        top_p=top_p,\n",
    "        max_tokens=max_tokens\n",
    "    )\n",
    "    response = completion.choices[0].message.content\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"./adv_data/new_generated_data_4o-mini_all.parquet\")\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data_cot = pd.DataFrame(columns=[\"QuestionText\", \"CorrectAnswer\", \"IncorrectAnswer\", \"MisconceptionId\", \"MisconceptionName\", \"UsedModel\", \"cot_input\", \"cot_output\"])\n",
    "new_data_cot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cot_prompt = \"\"\"You are an excellent teacher with a keen ability to understand students' thought processes and identify misconceptions. Your task is to analyze a student's incorrect answer to a question and explain the reasoning behind their mistake.\n",
    "\n",
    "You will be given the following information:\n",
    "<question>{{QuestionText}}</question>\n",
    "<correct_answer>{{CorrectAnswerText}}</correct_answer>\n",
    "<student_answer>{{IncorrectAnswerText}}</student_answer>\n",
    "\n",
    "Your job is to carefully analyze the student's answer and explain why they might have given this incorrect response. Compare the student's answer with the correct answer to identify the exact error(s) made.\n",
    "\n",
    "Provide your analysis within <analyze> tags. In your analysis:\n",
    "1. Break down the student's thought process step by step.\n",
    "2. Explain how the student's approach differs from the correct method.\n",
    "3. Suggest what concepts or skills the student might be struggling with.\n",
    "4. Control the length of your analysis to be within 300 words.\n",
    "\n",
    "Be thorough and empathetic in your analysis, considering various possible reasons for the student's mistake. Remember to view the problem from the student's perspective.\n",
    "\n",
    "After your detailed analysis, conclude with the following sentence:\n",
    "\"So the misconception the student made is: {{MisconceptionName}}\"\n",
    "\n",
    "Your entire response should be structured as follows:\n",
    "\n",
    "<analyze>\n",
    "[Your detailed analysis here]\n",
    "\n",
    "So the misconception the student made is: {{MisconceptionName}}\n",
    "</analyze>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"gpt-4o-mini\"\n",
    "\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    cot_input = cot_prompt.replace(\"{{QuestionText}}\", row[\"QuestionText\"]).replace(\"{{CorrectAnswerText}}\", row[\"CorrectAnswer\"]).replace(\"{{IncorrectAnswerText}}\", row[\"IncorrectAnswer\"]).replace(\"{{MisconceptionName}}\", row[\"MisconceptionName\"])\n",
    "    response = get_response_openai(model=model, prompt=cot_input)\n",
    "    response = re.search(r\"<analyze>(.*?)</analyze>\", response, re.DOTALL).group(1).strip()\n",
    "    new_data_cot_row = pd.DataFrame([{\n",
    "        \"QuestionText\": row[\"QuestionText\"],\n",
    "        \"CorrectAnswer\": row[\"CorrectAnswer\"],\n",
    "        \"IncorrectAnswer\": row[\"IncorrectAnswer\"],\n",
    "        \"MisconceptionId\": row[\"MisconceptionId\"],\n",
    "        \"MisconceptionName\": row[\"MisconceptionName\"],\n",
    "        \"UsedModel\": model,\n",
    "        \"cot_input\": cot_input,\n",
    "        \"cot_output\": response\n",
    "    }])\n",
    "    new_data_cot = pd.concat([new_data_cot, new_data_cot_row], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(new_data_cot[\"cot_output\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data_cot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data_cot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data_cot[\"cot_output\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data_cot.to_parquet(\"./adv_data/new_generated_data_4o-mini_all_cot.parquet\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
