{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import re\n",
    "import yaml\n",
    "import math\n",
    "import warnings\n",
    "from openai import OpenAI\n",
    "from groq import Groq\n",
    "from tqdm import tqdm\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = os.path.join(os.getcwd(), \"config.yaml\")\n",
    "\n",
    "with open(config_path, \"r\") as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "openai_api_key = config[\"openai\"][\"api_key\"]\n",
    "openai_organization = config[\"openai\"][\"organization\"]\n",
    "\n",
    "groq_api_key = config[\"groq\"][\"api_key\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_openai = OpenAI(api_key=openai_api_key, organization=openai_organization)\n",
    "client_groq = Groq(api_key=groq_api_key)\n",
    "\n",
    "def get_response_openai(model, prompt, temperature=0.7, top_p=0.95, max_tokens=1024):\n",
    "    completion = client_openai.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=temperature,\n",
    "        top_p=top_p,\n",
    "        max_tokens=max_tokens\n",
    "    )\n",
    "    response = completion.choices[0].message.content\n",
    "    return response\n",
    "\n",
    "\n",
    "def get_response_groq(model, prompt, temperature=0.7, top_p=0.95, max_tokens=1024):\n",
    "    completion = client_groq.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=temperature,\n",
    "        top_p=top_p,\n",
    "        max_tokens=max_tokens\n",
    "    )\n",
    "    response = completion.choices[0].message.content\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"./comp_data/train.csv\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "misconception_mapping = pd.read_csv(\"./comp_data/misconception_mapping.csv\")\n",
    "misconception_mapping.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train[\"ConstructId\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cot_data = pd.DataFrame(columns=[\"QuestionId\", \"ConstructId\", \"ConstructName\", \"SubjectId\", \"SubjectName\", \"QuestionText\", \"CorrectAnswer\", \"AnswerText\", \"IsCorrect\", \"MisconceptionId\", \"MisconceptionName\", \"cot_input\", \"cot_inference\"])\n",
    "cot_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowercase_first_letter(text):\n",
    "    if not text:\n",
    "        return text\n",
    "    return text[0].lower() + text[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cot_prompt = \"\"\"You are an excellent teacher with a keen ability to understand students' thought processes and identify misconceptions. Your task is to analyze a student's incorrect answer to a question and explain the reasoning behind their mistake.\n",
    "\n",
    "You will be given the following information:\n",
    "<question>{{QuestionText}}</question>\n",
    "<correct_answer>{{CorrectAnswerText}}</correct_answer>\n",
    "<student_answer>{{IncorrectAnswerText}}</student_answer>\n",
    "\n",
    "This question requires the student to {{ConstructName}}.\n",
    "\n",
    "Your job is to carefully analyze the student's answer and explain why they might have given this incorrect response. Compare the student's answer with the correct answer to identify the exact error(s) made.\n",
    "\n",
    "Provide your analysis within <analyze> tags. In your analysis:\n",
    "1. Break down the student's thought process step by step.\n",
    "2. Explain how the student's approach differs from the correct method.\n",
    "3. Suggest what concepts or skills the student might be struggling with.\n",
    "4. Control the length of your analysis to be within 300 words.\n",
    "\n",
    "Be thorough and empathetic in your analysis, considering various possible reasons for the student's mistake. Remember to view the problem from the student's perspective.\n",
    "\n",
    "After your detailed analysis, conclude with the following sentence:\n",
    "\"So the misconception the student made is: {{MisconceptionName}}\"\n",
    "\n",
    "Your entire response should be structured as follows:\n",
    "\n",
    "<analyze>\n",
    "[Your detailed analysis here]\n",
    "\n",
    "So the misconception the student made is: {{MisconceptionName}}\n",
    "</analyze>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(misconception_mapping[misconception_mapping[\"MisconceptionId\"] == 1][\"MisconceptionName\"].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = train[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use OpenAI Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in tqdm(train.iterrows(), total=len(train)):\n",
    "    try:\n",
    "        if row[\"CorrectAnswer\"] == \"A\":\n",
    "            if math.isnan(row[\"MisconceptionBId\"]) is False:\n",
    "                cot_input = cot_prompt.replace(\"{{ConstructName}}\", lowercase_first_letter(row[\"ConstructName\"])).replace(\"{{QuestionText}}\", row[\"QuestionText\"]).replace(\"{{CorrectAnswerText}}\", row[\"AnswerAText\"]) \\\n",
    "                .replace(\"{{IncorrectAnswerText}}\", row[\"AnswerBText\"]).replace(\"{{MisconceptionName}}\", misconception_mapping[misconception_mapping[\"MisconceptionId\"] == int(row[\"MisconceptionBId\"])][\"MisconceptionName\"].values[0])\n",
    "                response = get_response_openai(model=\"gpt-4o-mini\", prompt=cot_input)\n",
    "                response = re.search(r\"<analyze>(.*?)</analyze>\", response, re.DOTALL).group(1).strip()\n",
    "                new_row = pd.DataFrame([{\n",
    "                    \"QuestionId\": row[\"QuestionId\"],\n",
    "                    \"ConstructId\": row[\"ConstructId\"],\n",
    "                    \"ConstructName\": row[\"ConstructName\"],\n",
    "                    \"SubjectId\": row[\"SubjectId\"],\n",
    "                    \"SubjectName\": row[\"SubjectName\"],\n",
    "                    \"CorrectAnswer\": row[\"AnswerAText\"],\n",
    "                    \"QuestionText\": row[\"QuestionText\"],\n",
    "                    \"AnswerText\": row[\"AnswerBText\"],\n",
    "                    \"IsCorrect\": 0,\n",
    "                    \"MisconceptionId\": row[\"MisconceptionBId\"],\n",
    "                    \"MisconceptionName\": misconception_mapping[misconception_mapping[\"MisconceptionId\"] == int(row[\"MisconceptionBId\"])][\"MisconceptionName\"].values[0],\n",
    "                    \"cot_input\": cot_input,\n",
    "                    \"cot_inference\": response\n",
    "                }])\n",
    "                cot_data = pd.concat([cot_data, new_row], ignore_index=True)\n",
    "            if math.isnan(row[\"MisconceptionCId\"]) is False:\n",
    "                cot_input = cot_prompt.replace(\"{{ConstructName}}\", lowercase_first_letter(row[\"ConstructName\"])).replace(\"{{QuestionText}}\", row[\"QuestionText\"]).replace(\"{{CorrectAnswerText}}\", row[\"AnswerAText\"]) \\\n",
    "                .replace(\"{{IncorrectAnswerText}}\", row[\"AnswerCText\"]).replace(\"{{MisconceptionName}}\", misconception_mapping[misconception_mapping[\"MisconceptionId\"] == int(row[\"MisconceptionCId\"])][\"MisconceptionName\"].values[0])\n",
    "                response = get_response_openai(model=\"gpt-4o-mini\", prompt=cot_input)\n",
    "                response = re.search(r\"<analyze>(.*?)</analyze>\", response, re.DOTALL).group(1).strip()\n",
    "                new_row = pd.DataFrame([{\n",
    "                    \"QuestionId\": row[\"QuestionId\"],\n",
    "                    \"ConstructId\": row[\"ConstructId\"],\n",
    "                    \"ConstructName\": row[\"ConstructName\"],\n",
    "                    \"SubjectId\": row[\"SubjectId\"],\n",
    "                    \"SubjectName\": row[\"SubjectName\"],\n",
    "                    \"CorrectAnswer\": row[\"AnswerAText\"],\n",
    "                    \"QuestionText\": row[\"QuestionText\"],\n",
    "                    \"AnswerText\": row[\"AnswerCText\"],\n",
    "                    \"IsCorrect\": 0,\n",
    "                    \"MisconceptionId\": row[\"MisconceptionCId\"],\n",
    "                    \"MisconceptionName\": misconception_mapping[misconception_mapping[\"MisconceptionId\"] == int(row[\"MisconceptionCId\"])][\"MisconceptionName\"].values[0],\n",
    "                    \"cot_input\": cot_input,\n",
    "                    \"cot_inference\": response\n",
    "                }])\n",
    "                cot_data = pd.concat([cot_data, new_row], ignore_index=True)\n",
    "            if math.isnan(row[\"MisconceptionDId\"]) is False:\n",
    "                cot_input = cot_prompt.replace(\"{{ConstructName}}\", lowercase_first_letter(row[\"ConstructName\"])).replace(\"{{QuestionText}}\", row[\"QuestionText\"]).replace(\"{{CorrectAnswerText}}\", row[\"AnswerAText\"]) \\\n",
    "                .replace(\"{{IncorrectAnswerText}}\", row[\"AnswerDText\"]).replace(\"{{MisconceptionName}}\", misconception_mapping[misconception_mapping[\"MisconceptionId\"] == int(row[\"MisconceptionDId\"])][\"MisconceptionName\"].values[0])\n",
    "                response = get_response_openai(model=\"gpt-4o-mini\", prompt=cot_input)\n",
    "                response = re.search(r\"<analyze>(.*?)</analyze>\", response, re.DOTALL).group(1).strip()\n",
    "                new_row = pd.DataFrame([{\n",
    "                    \"QuestionId\": row[\"QuestionId\"],\n",
    "                    \"ConstructId\": row[\"ConstructId\"],\n",
    "                    \"ConstructName\": row[\"ConstructName\"],\n",
    "                    \"SubjectId\": row[\"SubjectId\"],\n",
    "                    \"SubjectName\": row[\"SubjectName\"],\n",
    "                    \"CorrectAnswer\": row[\"AnswerAText\"],\n",
    "                    \"QuestionText\": row[\"QuestionText\"],\n",
    "                    \"AnswerText\": row[\"AnswerDText\"],\n",
    "                    \"IsCorrect\": 0,\n",
    "                    \"MisconceptionId\": row[\"MisconceptionDId\"],\n",
    "                    \"MisconceptionName\": misconception_mapping[misconception_mapping[\"MisconceptionId\"] == int(row[\"MisconceptionDId\"])][\"MisconceptionName\"].values[0],\n",
    "                    \"cot_input\": cot_input,\n",
    "                    \"cot_inference\": response\n",
    "                }])\n",
    "                cot_data = pd.concat([cot_data, new_row], ignore_index=True)\n",
    "        elif row[\"CorrectAnswer\"] == \"B\":\n",
    "            if math.isnan(row[\"MisconceptionAId\"]) is False:\n",
    "                cot_input = cot_prompt.replace(\"{{ConstructName}}\", lowercase_first_letter(row[\"ConstructName\"])).replace(\"{{QuestionText}}\", row[\"QuestionText\"]).replace(\"{{CorrectAnswerText}}\", row[\"AnswerBText\"]) \\\n",
    "                .replace(\"{{IncorrectAnswerText}}\", row[\"AnswerAText\"]).replace(\"{{MisconceptionName}}\", misconception_mapping[misconception_mapping[\"MisconceptionId\"] == int(row[\"MisconceptionAId\"])][\"MisconceptionName\"].values[0])\n",
    "                response = get_response_openai(model=\"gpt-4o-mini\", prompt=cot_input)\n",
    "                response = re.search(r\"<analyze>(.*?)</analyze>\", response, re.DOTALL).group(1).strip()\n",
    "                new_row = pd.DataFrame([{\n",
    "                    \"QuestionId\": row[\"QuestionId\"],\n",
    "                    \"ConstructId\": row[\"ConstructId\"],\n",
    "                    \"ConstructName\": row[\"ConstructName\"],\n",
    "                    \"SubjectId\": row[\"SubjectId\"],\n",
    "                    \"SubjectName\": row[\"SubjectName\"],\n",
    "                    \"CorrectAnswer\": row[\"AnswerBText\"],\n",
    "                    \"QuestionText\": row[\"QuestionText\"],\n",
    "                    \"AnswerText\": row[\"AnswerAText\"],\n",
    "                    \"IsCorrect\": 0,\n",
    "                    \"MisconceptionId\": row[\"MisconceptionAId\"],\n",
    "                    \"MisconceptionName\": misconception_mapping[misconception_mapping[\"MisconceptionId\"] == int(row[\"MisconceptionAId\"])][\"MisconceptionName\"].values[0],\n",
    "                    \"cot_input\": cot_input,\n",
    "                    \"cot_inference\": response\n",
    "                }])\n",
    "                cot_data = pd.concat([cot_data, new_row], ignore_index=True)\n",
    "            if math.isnan(row[\"MisconceptionCId\"]) is False:\n",
    "                cot_input = cot_prompt.replace(\"{{ConstructName}}\", lowercase_first_letter(row[\"ConstructName\"])).replace(\"{{QuestionText}}\", row[\"QuestionText\"]).replace(\"{{CorrectAnswerText}}\", row[\"AnswerBText\"]) \\\n",
    "                .replace(\"{{IncorrectAnswerText}}\", row[\"AnswerCText\"]).replace(\"{{MisconceptionName}}\", misconception_mapping[misconception_mapping[\"MisconceptionId\"] == int(row[\"MisconceptionCId\"])][\"MisconceptionName\"].values[0])\n",
    "                response = get_response_openai(model=\"gpt-4o-mini\", prompt=cot_input)\n",
    "                response = re.search(r\"<analyze>(.*?)</analyze>\", response, re.DOTALL).group(1).strip()\n",
    "                new_row = pd.DataFrame([{\n",
    "                    \"QuestionId\": row[\"QuestionId\"],\n",
    "                    \"ConstructId\": row[\"ConstructId\"],\n",
    "                    \"ConstructName\": row[\"ConstructName\"],\n",
    "                    \"SubjectId\": row[\"SubjectId\"],\n",
    "                    \"SubjectName\": row[\"SubjectName\"],\n",
    "                    \"CorrectAnswer\": row[\"AnswerBText\"],\n",
    "                    \"QuestionText\": row[\"QuestionText\"],\n",
    "                    \"AnswerText\": row[\"AnswerCText\"],\n",
    "                    \"IsCorrect\": 0,\n",
    "                    \"MisconceptionId\": row[\"MisconceptionCId\"],\n",
    "                    \"MisconceptionName\": misconception_mapping[misconception_mapping[\"MisconceptionId\"] == int(row[\"MisconceptionCId\"])][\"MisconceptionName\"].values[0],\n",
    "                    \"cot_input\": cot_input,\n",
    "                    \"cot_inference\": response\n",
    "                }])\n",
    "                cot_data = pd.concat([cot_data, new_row], ignore_index=True)\n",
    "            if math.isnan(row[\"MisconceptionDId\"]) is False:\n",
    "                cot_input = cot_prompt.replace(\"{{ConstructName}}\", lowercase_first_letter(row[\"ConstructName\"])).replace(\"{{QuestionText}}\", row[\"QuestionText\"]).replace(\"{{CorrectAnswerText}}\", row[\"AnswerBText\"]) \\\n",
    "                .replace(\"{{IncorrectAnswerText}}\", row[\"AnswerDText\"]).replace(\"{{MisconceptionName}}\", misconception_mapping[misconception_mapping[\"MisconceptionId\"] == int(row[\"MisconceptionDId\"])][\"MisconceptionName\"].values[0])\n",
    "                response = get_response_openai(model=\"gpt-4o-mini\", prompt=cot_input)\n",
    "                response = re.search(r\"<analyze>(.*?)</analyze>\", response, re.DOTALL).group(1).strip()\n",
    "                new_row = pd.DataFrame([{\n",
    "                    \"QuestionId\": row[\"QuestionId\"],\n",
    "                    \"ConstructId\": row[\"ConstructId\"],\n",
    "                    \"ConstructName\": row[\"ConstructName\"],\n",
    "                    \"SubjectId\": row[\"SubjectId\"],\n",
    "                    \"SubjectName\": row[\"SubjectName\"],\n",
    "                    \"CorrectAnswer\": row[\"AnswerBText\"],\n",
    "                    \"QuestionText\": row[\"QuestionText\"],\n",
    "                    \"AnswerText\": row[\"AnswerDText\"],\n",
    "                    \"IsCorrect\": 0,\n",
    "                    \"MisconceptionId\": row[\"MisconceptionDId\"],\n",
    "                    \"MisconceptionName\": misconception_mapping[misconception_mapping[\"MisconceptionId\"] == int(row[\"MisconceptionDId\"])][\"MisconceptionName\"].values[0],\n",
    "                    \"cot_input\": cot_input,\n",
    "                    \"cot_inference\": response\n",
    "                }])\n",
    "                cot_data = pd.concat([cot_data, new_row], ignore_index=True)\n",
    "        elif row[\"CorrectAnswer\"] == \"C\":\n",
    "            if math.isnan(row[\"MisconceptionAId\"]) is False:\n",
    "                cot_input = cot_prompt.replace(\"{{ConstructName}}\", lowercase_first_letter(row[\"ConstructName\"])).replace(\"{{QuestionText}}\", row[\"QuestionText\"]).replace(\"{{CorrectAnswerText}}\", row[\"AnswerCText\"]) \\\n",
    "                .replace(\"{{IncorrectAnswerText}}\", row[\"AnswerAText\"]).replace(\"{{MisconceptionName}}\", misconception_mapping[misconception_mapping[\"MisconceptionId\"] == int(row[\"MisconceptionAId\"])][\"MisconceptionName\"].values[0])\n",
    "                response = get_response_openai(model=\"gpt-4o-mini\", prompt=cot_input)\n",
    "                response = re.search(r\"<analyze>(.*?)</analyze>\", response, re.DOTALL).group(1).strip()\n",
    "                new_row = pd.DataFrame([{\n",
    "                    \"QuestionId\": row[\"QuestionId\"],\n",
    "                    \"ConstructId\": row[\"ConstructId\"],\n",
    "                    \"ConstructName\": row[\"ConstructName\"],\n",
    "                    \"SubjectId\": row[\"SubjectId\"],\n",
    "                    \"SubjectName\": row[\"SubjectName\"],\n",
    "                    \"CorrectAnswer\": row[\"AnswerCText\"],\n",
    "                    \"QuestionText\": row[\"QuestionText\"],\n",
    "                    \"AnswerText\": row[\"AnswerAText\"],\n",
    "                    \"IsCorrect\": 0,\n",
    "                    \"MisconceptionId\": row[\"MisconceptionAId\"],\n",
    "                    \"MisconceptionName\": misconception_mapping[misconception_mapping[\"MisconceptionId\"] == int(row[\"MisconceptionAId\"])][\"MisconceptionName\"].values[0],\n",
    "                    \"cot_input\": cot_input,\n",
    "                    \"cot_inference\": response\n",
    "                }])\n",
    "                cot_data = pd.concat([cot_data, new_row], ignore_index=True)\n",
    "            if math.isnan(row[\"MisconceptionBId\"]) is False:\n",
    "                cot_input = cot_prompt.replace(\"{{ConstructName}}\", lowercase_first_letter(row[\"ConstructName\"])).replace(\"{{QuestionText}}\", row[\"QuestionText\"]).replace(\"{{CorrectAnswerText}}\", row[\"AnswerCText\"]) \\\n",
    "                .replace(\"{{IncorrectAnswerText}}\", row[\"AnswerBText\"]).replace(\"{{MisconceptionName}}\", misconception_mapping[misconception_mapping[\"MisconceptionId\"] == int(row[\"MisconceptionBId\"])][\"MisconceptionName\"].values[0])\n",
    "                response = get_response_openai(model=\"gpt-4o-mini\", prompt=cot_input)\n",
    "                response = re.search(r\"<analyze>(.*?)</analyze>\", response, re.DOTALL).group(1).strip()\n",
    "                new_row = pd.DataFrame([{\n",
    "                    \"QuestionId\": row[\"QuestionId\"],\n",
    "                    \"ConstructId\": row[\"ConstructId\"],\n",
    "                    \"ConstructName\": row[\"ConstructName\"],\n",
    "                    \"SubjectId\": row[\"SubjectId\"],\n",
    "                    \"SubjectName\": row[\"SubjectName\"],\n",
    "                    \"CorrectAnswer\": row[\"AnswerCText\"],\n",
    "                    \"QuestionText\": row[\"QuestionText\"],\n",
    "                    \"AnswerText\": row[\"AnswerBText\"],\n",
    "                    \"IsCorrect\": 0,\n",
    "                    \"MisconceptionId\": row[\"MisconceptionBId\"],\n",
    "                    \"MisconceptionName\": misconception_mapping[misconception_mapping[\"MisconceptionId\"] == int(row[\"MisconceptionBId\"])][\"MisconceptionName\"].values[0],\n",
    "                    \"cot_input\": cot_input,\n",
    "                    \"cot_inference\": response\n",
    "                }])\n",
    "                cot_data = pd.concat([cot_data, new_row], ignore_index=True)\n",
    "            if math.isnan(row[\"MisconceptionDId\"]) is False:\n",
    "                cot_input = cot_prompt.replace(\"{{ConstructName}}\", lowercase_first_letter(row[\"ConstructName\"])).replace(\"{{QuestionText}}\", row[\"QuestionText\"]).replace(\"{{CorrectAnswerText}}\", row[\"AnswerCText\"]) \\\n",
    "                .replace(\"{{IncorrectAnswerText}}\", row[\"AnswerDText\"]).replace(\"{{MisconceptionName}}\", misconception_mapping[misconception_mapping[\"MisconceptionId\"] == int(row[\"MisconceptionDId\"])][\"MisconceptionName\"].values[0])\n",
    "                response = get_response_openai(model=\"gpt-4o-mini\", prompt=cot_input)\n",
    "                response = re.search(r\"<analyze>(.*?)</analyze>\", response, re.DOTALL).group(1).strip()\n",
    "                new_row = pd.DataFrame([{\n",
    "                    \"QuestionId\": row[\"QuestionId\"],\n",
    "                    \"ConstructId\": row[\"ConstructId\"],\n",
    "                    \"ConstructName\": row[\"ConstructName\"],\n",
    "                    \"SubjectId\": row[\"SubjectId\"],\n",
    "                    \"SubjectName\": row[\"SubjectName\"],\n",
    "                    \"CorrectAnswer\": row[\"AnswerCText\"],\n",
    "                    \"QuestionText\": row[\"QuestionText\"],\n",
    "                    \"AnswerText\": row[\"AnswerDText\"],\n",
    "                    \"IsCorrect\": 0,\n",
    "                    \"MisconceptionId\": row[\"MisconceptionDId\"],\n",
    "                    \"MisconceptionName\": misconception_mapping[misconception_mapping[\"MisconceptionId\"] == int(row[\"MisconceptionDId\"])][\"MisconceptionName\"].values[0],\n",
    "                    \"cot_input\": cot_input,\n",
    "                    \"cot_inference\": response\n",
    "                }])\n",
    "                cot_data = pd.concat([cot_data, new_row], ignore_index=True)\n",
    "        elif row[\"CorrectAnswer\"] == \"D\":\n",
    "            if math.isnan(row[\"MisconceptionAId\"]) is False:\n",
    "                cot_input = cot_prompt.replace(\"{{ConstructName}}\", lowercase_first_letter(row[\"ConstructName\"])).replace(\"{{QuestionText}}\", row[\"QuestionText\"]).replace(\"{{CorrectAnswerText}}\", row[\"AnswerDText\"]) \\\n",
    "                .replace(\"{{IncorrectAnswerText}}\", row[\"AnswerAText\"]).replace(\"{{MisconceptionName}}\", misconception_mapping[misconception_mapping[\"MisconceptionId\"] == int(row[\"MisconceptionAId\"])][\"MisconceptionName\"].values[0])\n",
    "                response = get_response_openai(model=\"gpt-4o-mini\", prompt=cot_input)\n",
    "                response = re.search(r\"<analyze>(.*?)</analyze>\", response, re.DOTALL).group(1).strip()\n",
    "                new_row = pd.DataFrame([{\n",
    "                    \"QuestionId\": row[\"QuestionId\"],\n",
    "                    \"ConstructId\": row[\"ConstructId\"],\n",
    "                    \"ConstructName\": row[\"ConstructName\"],\n",
    "                    \"SubjectId\": row[\"SubjectId\"],\n",
    "                    \"SubjectName\": row[\"SubjectName\"],\n",
    "                    \"CorrectAnswer\": row[\"AnswerDText\"],\n",
    "                    \"QuestionText\": row[\"QuestionText\"],\n",
    "                    \"AnswerText\": row[\"AnswerAText\"],\n",
    "                    \"IsCorrect\": 0,\n",
    "                    \"MisconceptionId\": row[\"MisconceptionAId\"],\n",
    "                    \"MisconceptionName\": misconception_mapping[misconception_mapping[\"MisconceptionId\"] == int(row[\"MisconceptionAId\"])][\"MisconceptionName\"].values[0],\n",
    "                    \"cot_input\": cot_input,\n",
    "                    \"cot_inference\": response\n",
    "                }])\n",
    "                cot_data = pd.concat([cot_data, new_row], ignore_index=True)\n",
    "            if math.isnan(row[\"MisconceptionBId\"]) is False:\n",
    "                cot_input = cot_prompt.replace(\"{{ConstructName}}\", lowercase_first_letter(row[\"ConstructName\"])).replace(\"{{QuestionText}}\", row[\"QuestionText\"]).replace(\"{{CorrectAnswerText}}\", row[\"AnswerDText\"]) \\\n",
    "                .replace(\"{{IncorrectAnswerText}}\", row[\"AnswerBText\"]).replace(\"{{MisconceptionName}}\", misconception_mapping[misconception_mapping[\"MisconceptionId\"] == int(row[\"MisconceptionBId\"])][\"MisconceptionName\"].values[0])\n",
    "                response = get_response_openai(model=\"gpt-4o-mini\", prompt=cot_input)\n",
    "                response = re.search(r\"<analyze>(.*?)</analyze>\", response, re.DOTALL).group(1).strip()\n",
    "                new_row = pd.DataFrame([{\n",
    "                    \"QuestionId\": row[\"QuestionId\"],\n",
    "                    \"ConstructId\": row[\"ConstructId\"],\n",
    "                    \"ConstructName\": row[\"ConstructName\"],\n",
    "                    \"SubjectId\": row[\"SubjectId\"],\n",
    "                    \"SubjectName\": row[\"SubjectName\"],\n",
    "                    \"CorrectAnswer\": row[\"AnswerDText\"],\n",
    "                    \"QuestionText\": row[\"QuestionText\"],\n",
    "                    \"AnswerText\": row[\"AnswerBText\"],\n",
    "                    \"IsCorrect\": 0,\n",
    "                    \"MisconceptionId\": row[\"MisconceptionBId\"],\n",
    "                    \"MisconceptionName\": misconception_mapping[misconception_mapping[\"MisconceptionId\"] == int(row[\"MisconceptionBId\"])][\"MisconceptionName\"].values[0],\n",
    "                    \"cot_input\": cot_input,\n",
    "                    \"cot_inference\": response\n",
    "                }])\n",
    "                cot_data = pd.concat([cot_data, new_row], ignore_index=True)\n",
    "            if math.isnan(row[\"MisconceptionCId\"]) is False:\n",
    "                cot_input = cot_prompt.replace(\"{{ConstructName}}\", lowercase_first_letter(row[\"ConstructName\"])).replace(\"{{QuestionText}}\", row[\"QuestionText\"]).replace(\"{{CorrectAnswerText}}\", row[\"AnswerDText\"]) \\\n",
    "                .replace(\"{{IncorrectAnswerText}}\", row[\"AnswerCText\"]).replace(\"{{MisconceptionName}}\", misconception_mapping[misconception_mapping[\"MisconceptionId\"] == int(row[\"MisconceptionCId\"])][\"MisconceptionName\"].values[0])\n",
    "                response = get_response_openai(model=\"gpt-4o-mini\", prompt=cot_input)\n",
    "                response = re.search(r\"<analyze>(.*?)</analyze>\", response, re.DOTALL).group(1).strip()\n",
    "                new_row = pd.DataFrame([{\n",
    "                    \"QuestionId\": row[\"QuestionId\"],\n",
    "                    \"ConstructId\": row[\"ConstructId\"],\n",
    "                    \"ConstructName\": row[\"ConstructName\"],\n",
    "                    \"SubjectId\": row[\"SubjectId\"],\n",
    "                    \"SubjectName\": row[\"SubjectName\"],\n",
    "                    \"CorrectAnswer\": row[\"AnswerDText\"],\n",
    "                    \"QuestionText\": row[\"QuestionText\"],\n",
    "                    \"AnswerText\": row[\"AnswerCText\"],\n",
    "                    \"IsCorrect\": 0,\n",
    "                    \"MisconceptionId\": row[\"MisconceptionCId\"],\n",
    "                    \"MisconceptionName\": misconception_mapping[misconception_mapping[\"MisconceptionId\"] == int(row[\"MisconceptionCId\"])][\"MisconceptionName\"].values[0],\n",
    "                    \"cot_input\": cot_input,\n",
    "                    \"cot_inference\": response\n",
    "                }])\n",
    "                cot_data = pd.concat([cot_data, new_row], ignore_index=True)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use Groq Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in tqdm(train.iterrows(), total=len(train)):\n",
    "    try:\n",
    "        if row[\"CorrectAnswer\"] == \"A\":\n",
    "            if math.isnan(row[\"MisconceptionBId\"]) is False:\n",
    "                cot_input = cot_prompt.replace(\"{{ConstructName}}\", lowercase_first_letter(row[\"ConstructName\"])).replace(\"{{QuestionText}}\", row[\"QuestionText\"]).replace(\"{{CorrectAnswerText}}\", row[\"AnswerAText\"]) \\\n",
    "                .replace(\"{{IncorrectAnswerText}}\", row[\"AnswerBText\"]).replace(\"{{MisconceptionName}}\", misconception_mapping[misconception_mapping[\"MisconceptionId\"] == int(row[\"MisconceptionBId\"])][\"MisconceptionName\"].values[0])\n",
    "                response = get_response_groq(model=\"llama-3.1-70b-versatile\", prompt=cot_input)\n",
    "                response = re.search(r\"<analyze>(.*?)</analyze>\", response, re.DOTALL).group(1).strip()\n",
    "                new_row = pd.DataFrame([{\n",
    "                    \"QuestionId\": row[\"QuestionId\"],\n",
    "                    \"ConstructId\": row[\"ConstructId\"],\n",
    "                    \"ConstructName\": row[\"ConstructName\"],\n",
    "                    \"SubjectId\": row[\"SubjectId\"],\n",
    "                    \"SubjectName\": row[\"SubjectName\"],\n",
    "                    \"CorrectAnswer\": row[\"AnswerAText\"],\n",
    "                    \"QuestionText\": row[\"QuestionText\"],\n",
    "                    \"AnswerText\": row[\"AnswerBText\"],\n",
    "                    \"IsCorrect\": 0,\n",
    "                    \"MisconceptionId\": row[\"MisconceptionBId\"],\n",
    "                    \"MisconceptionName\": misconception_mapping[misconception_mapping[\"MisconceptionId\"] == int(row[\"MisconceptionBId\"])][\"MisconceptionName\"].values[0],\n",
    "                    \"cot_input\": cot_input,\n",
    "                    \"cot_inference\": response\n",
    "                }])\n",
    "                cot_data = pd.concat([cot_data, new_row], ignore_index=True)\n",
    "            if math.isnan(row[\"MisconceptionCId\"]) is False:\n",
    "                cot_input = cot_prompt.replace(\"{{ConstructName}}\", lowercase_first_letter(row[\"ConstructName\"])).replace(\"{{QuestionText}}\", row[\"QuestionText\"]).replace(\"{{CorrectAnswerText}}\", row[\"AnswerAText\"]) \\\n",
    "                .replace(\"{{IncorrectAnswerText}}\", row[\"AnswerCText\"]).replace(\"{{MisconceptionName}}\", misconception_mapping[misconception_mapping[\"MisconceptionId\"] == int(row[\"MisconceptionCId\"])][\"MisconceptionName\"].values[0])\n",
    "                response = get_response_groq(model=\"llama-3.1-70b-versatile\", prompt=cot_input)\n",
    "                response = re.search(r\"<analyze>(.*?)</analyze>\", response, re.DOTALL).group(1).strip()\n",
    "                new_row = pd.DataFrame([{\n",
    "                    \"QuestionId\": row[\"QuestionId\"],\n",
    "                    \"ConstructId\": row[\"ConstructId\"],\n",
    "                    \"ConstructName\": row[\"ConstructName\"],\n",
    "                    \"SubjectId\": row[\"SubjectId\"],\n",
    "                    \"SubjectName\": row[\"SubjectName\"],\n",
    "                    \"CorrectAnswer\": row[\"AnswerAText\"],\n",
    "                    \"QuestionText\": row[\"QuestionText\"],\n",
    "                    \"AnswerText\": row[\"AnswerCText\"],\n",
    "                    \"IsCorrect\": 0,\n",
    "                    \"MisconceptionId\": row[\"MisconceptionCId\"],\n",
    "                    \"MisconceptionName\": misconception_mapping[misconception_mapping[\"MisconceptionId\"] == int(row[\"MisconceptionCId\"])][\"MisconceptionName\"].values[0],\n",
    "                    \"cot_input\": cot_input,\n",
    "                    \"cot_inference\": response\n",
    "                }])\n",
    "                cot_data = pd.concat([cot_data, new_row], ignore_index=True)\n",
    "            if math.isnan(row[\"MisconceptionDId\"]) is False:\n",
    "                cot_input = cot_prompt.replace(\"{{ConstructName}}\", lowercase_first_letter(row[\"ConstructName\"])).replace(\"{{QuestionText}}\", row[\"QuestionText\"]).replace(\"{{CorrectAnswerText}}\", row[\"AnswerAText\"]) \\\n",
    "                .replace(\"{{IncorrectAnswerText}}\", row[\"AnswerDText\"]).replace(\"{{MisconceptionName}}\", misconception_mapping[misconception_mapping[\"MisconceptionId\"] == int(row[\"MisconceptionDId\"])][\"MisconceptionName\"].values[0])\n",
    "                response = get_response_groq(model=\"llama-3.1-70b-versatile\", prompt=cot_input)\n",
    "                response = re.search(r\"<analyze>(.*?)</analyze>\", response, re.DOTALL).group(1).strip()\n",
    "                new_row = pd.DataFrame([{\n",
    "                    \"QuestionId\": row[\"QuestionId\"],\n",
    "                    \"ConstructId\": row[\"ConstructId\"],\n",
    "                    \"ConstructName\": row[\"ConstructName\"],\n",
    "                    \"SubjectId\": row[\"SubjectId\"],\n",
    "                    \"SubjectName\": row[\"SubjectName\"],\n",
    "                    \"CorrectAnswer\": row[\"AnswerAText\"],\n",
    "                    \"QuestionText\": row[\"QuestionText\"],\n",
    "                    \"AnswerText\": row[\"AnswerDText\"],\n",
    "                    \"IsCorrect\": 0,\n",
    "                    \"MisconceptionId\": row[\"MisconceptionDId\"],\n",
    "                    \"MisconceptionName\": misconception_mapping[misconception_mapping[\"MisconceptionId\"] == int(row[\"MisconceptionDId\"])][\"MisconceptionName\"].values[0],\n",
    "                    \"cot_input\": cot_input,\n",
    "                    \"cot_inference\": response\n",
    "                }])\n",
    "                cot_data = pd.concat([cot_data, new_row], ignore_index=True)\n",
    "        elif row[\"CorrectAnswer\"] == \"B\":\n",
    "            if math.isnan(row[\"MisconceptionAId\"]) is False:\n",
    "                cot_input = cot_prompt.replace(\"{{ConstructName}}\", lowercase_first_letter(row[\"ConstructName\"])).replace(\"{{QuestionText}}\", row[\"QuestionText\"]).replace(\"{{CorrectAnswerText}}\", row[\"AnswerBText\"]) \\\n",
    "                .replace(\"{{IncorrectAnswerText}}\", row[\"AnswerAText\"]).replace(\"{{MisconceptionName}}\", misconception_mapping[misconception_mapping[\"MisconceptionId\"] == int(row[\"MisconceptionAId\"])][\"MisconceptionName\"].values[0])\n",
    "                response = get_response_groq(model=\"llama-3.1-70b-versatile\", prompt=cot_input)\n",
    "                response = re.search(r\"<analyze>(.*?)</analyze>\", response, re.DOTALL).group(1).strip()\n",
    "                new_row = pd.DataFrame([{\n",
    "                    \"QuestionId\": row[\"QuestionId\"],\n",
    "                    \"ConstructId\": row[\"ConstructId\"],\n",
    "                    \"ConstructName\": row[\"ConstructName\"],\n",
    "                    \"SubjectId\": row[\"SubjectId\"],\n",
    "                    \"SubjectName\": row[\"SubjectName\"],\n",
    "                    \"CorrectAnswer\": row[\"AnswerBText\"],\n",
    "                    \"QuestionText\": row[\"QuestionText\"],\n",
    "                    \"AnswerText\": row[\"AnswerAText\"],\n",
    "                    \"IsCorrect\": 0,\n",
    "                    \"MisconceptionId\": row[\"MisconceptionAId\"],\n",
    "                    \"MisconceptionName\": misconception_mapping[misconception_mapping[\"MisconceptionId\"] == int(row[\"MisconceptionAId\"])][\"MisconceptionName\"].values[0],\n",
    "                    \"cot_input\": cot_input,\n",
    "                    \"cot_inference\": response\n",
    "                }])\n",
    "                cot_data = pd.concat([cot_data, new_row], ignore_index=True)\n",
    "            if math.isnan(row[\"MisconceptionCId\"]) is False:\n",
    "                cot_input = cot_prompt.replace(\"{{ConstructName}}\", lowercase_first_letter(row[\"ConstructName\"])).replace(\"{{QuestionText}}\", row[\"QuestionText\"]).replace(\"{{CorrectAnswerText}}\", row[\"AnswerBText\"]) \\\n",
    "                .replace(\"{{IncorrectAnswerText}}\", row[\"AnswerCText\"]).replace(\"{{MisconceptionName}}\", misconception_mapping[misconception_mapping[\"MisconceptionId\"] == int(row[\"MisconceptionCId\"])][\"MisconceptionName\"].values[0])\n",
    "                response = get_response_groq(model=\"llama-3.1-70b-versatile\", prompt=cot_input)\n",
    "                response = re.search(r\"<analyze>(.*?)</analyze>\", response, re.DOTALL).group(1).strip()\n",
    "                new_row = pd.DataFrame([{\n",
    "                    \"QuestionId\": row[\"QuestionId\"],\n",
    "                    \"ConstructId\": row[\"ConstructId\"],\n",
    "                    \"ConstructName\": row[\"ConstructName\"],\n",
    "                    \"SubjectId\": row[\"SubjectId\"],\n",
    "                    \"SubjectName\": row[\"SubjectName\"],\n",
    "                    \"CorrectAnswer\": row[\"AnswerBText\"],\n",
    "                    \"QuestionText\": row[\"QuestionText\"],\n",
    "                    \"AnswerText\": row[\"AnswerCText\"],\n",
    "                    \"IsCorrect\": 0,\n",
    "                    \"MisconceptionId\": row[\"MisconceptionCId\"],\n",
    "                    \"MisconceptionName\": misconception_mapping[misconception_mapping[\"MisconceptionId\"] == int(row[\"MisconceptionCId\"])][\"MisconceptionName\"].values[0],\n",
    "                    \"cot_input\": cot_input,\n",
    "                    \"cot_inference\": response\n",
    "                }])\n",
    "                cot_data = pd.concat([cot_data, new_row], ignore_index=True)\n",
    "            if math.isnan(row[\"MisconceptionDId\"]) is False:\n",
    "                cot_input = cot_prompt.replace(\"{{ConstructName}}\", lowercase_first_letter(row[\"ConstructName\"])).replace(\"{{QuestionText}}\", row[\"QuestionText\"]).replace(\"{{CorrectAnswerText}}\", row[\"AnswerBText\"]) \\\n",
    "                .replace(\"{{IncorrectAnswerText}}\", row[\"AnswerDText\"]).replace(\"{{MisconceptionName}}\", misconception_mapping[misconception_mapping[\"MisconceptionId\"] == int(row[\"MisconceptionDId\"])][\"MisconceptionName\"].values[0])\n",
    "                response = get_response_groq(model=\"llama-3.1-70b-versatile\", prompt=cot_input)\n",
    "                response = re.search(r\"<analyze>(.*?)</analyze>\", response, re.DOTALL).group(1).strip()\n",
    "                new_row = pd.DataFrame([{\n",
    "                    \"QuestionId\": row[\"QuestionId\"],\n",
    "                    \"ConstructId\": row[\"ConstructId\"],\n",
    "                    \"ConstructName\": row[\"ConstructName\"],\n",
    "                    \"SubjectId\": row[\"SubjectId\"],\n",
    "                    \"SubjectName\": row[\"SubjectName\"],\n",
    "                    \"CorrectAnswer\": row[\"AnswerBText\"],\n",
    "                    \"QuestionText\": row[\"QuestionText\"],\n",
    "                    \"AnswerText\": row[\"AnswerDText\"],\n",
    "                    \"IsCorrect\": 0,\n",
    "                    \"MisconceptionId\": row[\"MisconceptionDId\"],\n",
    "                    \"MisconceptionName\": misconception_mapping[misconception_mapping[\"MisconceptionId\"] == int(row[\"MisconceptionDId\"])][\"MisconceptionName\"].values[0],\n",
    "                    \"cot_input\": cot_input,\n",
    "                    \"cot_inference\": response\n",
    "                }])\n",
    "                cot_data = pd.concat([cot_data, new_row], ignore_index=True)\n",
    "        elif row[\"CorrectAnswer\"] == \"C\":\n",
    "            if math.isnan(row[\"MisconceptionAId\"]) is False:\n",
    "                cot_input = cot_prompt.replace(\"{{ConstructName}}\", lowercase_first_letter(row[\"ConstructName\"])).replace(\"{{QuestionText}}\", row[\"QuestionText\"]).replace(\"{{CorrectAnswerText}}\", row[\"AnswerCText\"]) \\\n",
    "                .replace(\"{{IncorrectAnswerText}}\", row[\"AnswerAText\"]).replace(\"{{MisconceptionName}}\", misconception_mapping[misconception_mapping[\"MisconceptionId\"] == int(row[\"MisconceptionAId\"])][\"MisconceptionName\"].values[0])\n",
    "                response = get_response_groq(model=\"llama-3.1-70b-versatile\", prompt=cot_input)\n",
    "                response = re.search(r\"<analyze>(.*?)</analyze>\", response, re.DOTALL).group(1).strip()\n",
    "                new_row = pd.DataFrame([{\n",
    "                    \"QuestionId\": row[\"QuestionId\"],\n",
    "                    \"ConstructId\": row[\"ConstructId\"],\n",
    "                    \"ConstructName\": row[\"ConstructName\"],\n",
    "                    \"SubjectId\": row[\"SubjectId\"],\n",
    "                    \"SubjectName\": row[\"SubjectName\"],\n",
    "                    \"CorrectAnswer\": row[\"AnswerCText\"],\n",
    "                    \"QuestionText\": row[\"QuestionText\"],\n",
    "                    \"AnswerText\": row[\"AnswerAText\"],\n",
    "                    \"IsCorrect\": 0,\n",
    "                    \"MisconceptionId\": row[\"MisconceptionAId\"],\n",
    "                    \"MisconceptionName\": misconception_mapping[misconception_mapping[\"MisconceptionId\"] == int(row[\"MisconceptionAId\"])][\"MisconceptionName\"].values[0],\n",
    "                    \"cot_input\": cot_input,\n",
    "                    \"cot_inference\": response\n",
    "                }])\n",
    "                cot_data = pd.concat([cot_data, new_row], ignore_index=True)\n",
    "            if math.isnan(row[\"MisconceptionBId\"]) is False:\n",
    "                cot_input = cot_prompt.replace(\"{{ConstructName}}\", lowercase_first_letter(row[\"ConstructName\"])).replace(\"{{QuestionText}}\", row[\"QuestionText\"]).replace(\"{{CorrectAnswerText}}\", row[\"AnswerCText\"]) \\\n",
    "                .replace(\"{{IncorrectAnswerText}}\", row[\"AnswerBText\"]).replace(\"{{MisconceptionName}}\", misconception_mapping[misconception_mapping[\"MisconceptionId\"] == int(row[\"MisconceptionBId\"])][\"MisconceptionName\"].values[0])\n",
    "                response = get_response_groq(model=\"llama-3.1-70b-versatile\", prompt=cot_input)\n",
    "                response = re.search(r\"<analyze>(.*?)</analyze>\", response, re.DOTALL).group(1).strip()\n",
    "                new_row = pd.DataFrame([{\n",
    "                    \"QuestionId\": row[\"QuestionId\"],\n",
    "                    \"ConstructId\": row[\"ConstructId\"],\n",
    "                    \"ConstructName\": row[\"ConstructName\"],\n",
    "                    \"SubjectId\": row[\"SubjectId\"],\n",
    "                    \"SubjectName\": row[\"SubjectName\"],\n",
    "                    \"CorrectAnswer\": row[\"AnswerCText\"],\n",
    "                    \"QuestionText\": row[\"QuestionText\"],\n",
    "                    \"AnswerText\": row[\"AnswerBText\"],\n",
    "                    \"IsCorrect\": 0,\n",
    "                    \"MisconceptionId\": row[\"MisconceptionBId\"],\n",
    "                    \"MisconceptionName\": misconception_mapping[misconception_mapping[\"MisconceptionId\"] == int(row[\"MisconceptionBId\"])][\"MisconceptionName\"].values[0],\n",
    "                    \"cot_input\": cot_input,\n",
    "                    \"cot_inference\": response\n",
    "                }])\n",
    "                cot_data = pd.concat([cot_data, new_row], ignore_index=True)\n",
    "            if math.isnan(row[\"MisconceptionDId\"]) is False:\n",
    "                cot_input = cot_prompt.replace(\"{{ConstructName}}\", lowercase_first_letter(row[\"ConstructName\"])).replace(\"{{QuestionText}}\", row[\"QuestionText\"]).replace(\"{{CorrectAnswerText}}\", row[\"AnswerCText\"]) \\\n",
    "                .replace(\"{{IncorrectAnswerText}}\", row[\"AnswerDText\"]).replace(\"{{MisconceptionName}}\", misconception_mapping[misconception_mapping[\"MisconceptionId\"] == int(row[\"MisconceptionDId\"])][\"MisconceptionName\"].values[0])\n",
    "                response = get_response_groq(model=\"llama-3.1-70b-versatile\", prompt=cot_input)\n",
    "                response = re.search(r\"<analyze>(.*?)</analyze>\", response, re.DOTALL).group(1).strip()\n",
    "                new_row = pd.DataFrame([{\n",
    "                    \"QuestionId\": row[\"QuestionId\"],\n",
    "                    \"ConstructId\": row[\"ConstructId\"],\n",
    "                    \"ConstructName\": row[\"ConstructName\"],\n",
    "                    \"SubjectId\": row[\"SubjectId\"],\n",
    "                    \"SubjectName\": row[\"SubjectName\"],\n",
    "                    \"CorrectAnswer\": row[\"AnswerCText\"],\n",
    "                    \"QuestionText\": row[\"QuestionText\"],\n",
    "                    \"AnswerText\": row[\"AnswerDText\"],\n",
    "                    \"IsCorrect\": 0,\n",
    "                    \"MisconceptionId\": row[\"MisconceptionDId\"],\n",
    "                    \"MisconceptionName\": misconception_mapping[misconception_mapping[\"MisconceptionId\"] == int(row[\"MisconceptionDId\"])][\"MisconceptionName\"].values[0],\n",
    "                    \"cot_input\": cot_input,\n",
    "                    \"cot_inference\": response\n",
    "                }])\n",
    "                cot_data = pd.concat([cot_data, new_row], ignore_index=True)\n",
    "        elif row[\"CorrectAnswer\"] == \"D\":\n",
    "            if math.isnan(row[\"MisconceptionAId\"]) is False:\n",
    "                cot_input = cot_prompt.replace(\"{{ConstructName}}\", lowercase_first_letter(row[\"ConstructName\"])).replace(\"{{QuestionText}}\", row[\"QuestionText\"]).replace(\"{{CorrectAnswerText}}\", row[\"AnswerDText\"]) \\\n",
    "                .replace(\"{{IncorrectAnswerText}}\", row[\"AnswerAText\"]).replace(\"{{MisconceptionName}}\", misconception_mapping[misconception_mapping[\"MisconceptionId\"] == int(row[\"MisconceptionAId\"])][\"MisconceptionName\"].values[0])\n",
    "                response = get_response_groq(model=\"llama-3.1-70b-versatile\", prompt=cot_input)\n",
    "                response = re.search(r\"<analyze>(.*?)</analyze>\", response, re.DOTALL).group(1).strip()\n",
    "                new_row = pd.DataFrame([{\n",
    "                    \"QuestionId\": row[\"QuestionId\"],\n",
    "                    \"ConstructId\": row[\"ConstructId\"],\n",
    "                    \"ConstructName\": row[\"ConstructName\"],\n",
    "                    \"SubjectId\": row[\"SubjectId\"],\n",
    "                    \"SubjectName\": row[\"SubjectName\"],\n",
    "                    \"CorrectAnswer\": row[\"AnswerDText\"],\n",
    "                    \"QuestionText\": row[\"QuestionText\"],\n",
    "                    \"AnswerText\": row[\"AnswerAText\"],\n",
    "                    \"IsCorrect\": 0,\n",
    "                    \"MisconceptionId\": row[\"MisconceptionAId\"],\n",
    "                    \"MisconceptionName\": misconception_mapping[misconception_mapping[\"MisconceptionId\"] == int(row[\"MisconceptionAId\"])][\"MisconceptionName\"].values[0],\n",
    "                    \"cot_input\": cot_input,\n",
    "                    \"cot_inference\": response\n",
    "                }])\n",
    "                cot_data = pd.concat([cot_data, new_row], ignore_index=True)\n",
    "            if math.isnan(row[\"MisconceptionBId\"]) is False:\n",
    "                cot_input = cot_prompt.replace(\"{{ConstructName}}\", lowercase_first_letter(row[\"ConstructName\"])).replace(\"{{QuestionText}}\", row[\"QuestionText\"]).replace(\"{{CorrectAnswerText}}\", row[\"AnswerDText\"]) \\\n",
    "                .replace(\"{{IncorrectAnswerText}}\", row[\"AnswerBText\"]).replace(\"{{MisconceptionName}}\", misconception_mapping[misconception_mapping[\"MisconceptionId\"] == int(row[\"MisconceptionBId\"])][\"MisconceptionName\"].values[0])\n",
    "                response = get_response_groq(model=\"llama-3.1-70b-versatile\", prompt=cot_input)\n",
    "                response = re.search(r\"<analyze>(.*?)</analyze>\", response, re.DOTALL).group(1).strip()\n",
    "                new_row = pd.DataFrame([{\n",
    "                    \"QuestionId\": row[\"QuestionId\"],\n",
    "                    \"ConstructId\": row[\"ConstructId\"],\n",
    "                    \"ConstructName\": row[\"ConstructName\"],\n",
    "                    \"SubjectId\": row[\"SubjectId\"],\n",
    "                    \"SubjectName\": row[\"SubjectName\"],\n",
    "                    \"CorrectAnswer\": row[\"AnswerDText\"],\n",
    "                    \"QuestionText\": row[\"QuestionText\"],\n",
    "                    \"AnswerText\": row[\"AnswerBText\"],\n",
    "                    \"IsCorrect\": 0,\n",
    "                    \"MisconceptionId\": row[\"MisconceptionBId\"],\n",
    "                    \"MisconceptionName\": misconception_mapping[misconception_mapping[\"MisconceptionId\"] == int(row[\"MisconceptionBId\"])][\"MisconceptionName\"].values[0],\n",
    "                    \"cot_input\": cot_input,\n",
    "                    \"cot_inference\": response\n",
    "                }])\n",
    "                cot_data = pd.concat([cot_data, new_row], ignore_index=True)\n",
    "            if math.isnan(row[\"MisconceptionCId\"]) is False:\n",
    "                cot_input = cot_prompt.replace(\"{{ConstructName}}\", lowercase_first_letter(row[\"ConstructName\"])).replace(\"{{QuestionText}}\", row[\"QuestionText\"]).replace(\"{{CorrectAnswerText}}\", row[\"AnswerDText\"]) \\\n",
    "                .replace(\"{{IncorrectAnswerText}}\", row[\"AnswerCText\"]).replace(\"{{MisconceptionName}}\", misconception_mapping[misconception_mapping[\"MisconceptionId\"] == int(row[\"MisconceptionCId\"])][\"MisconceptionName\"].values[0])\n",
    "                response = get_response_groq(model=\"llama-3.1-70b-versatile\", prompt=cot_input)\n",
    "                response = re.search(r\"<analyze>(.*?)</analyze>\", response, re.DOTALL).group(1).strip()\n",
    "                new_row = pd.DataFrame([{\n",
    "                    \"QuestionId\": row[\"QuestionId\"],\n",
    "                    \"ConstructId\": row[\"ConstructId\"],\n",
    "                    \"ConstructName\": row[\"ConstructName\"],\n",
    "                    \"SubjectId\": row[\"SubjectId\"],\n",
    "                    \"SubjectName\": row[\"SubjectName\"],\n",
    "                    \"CorrectAnswer\": row[\"AnswerDText\"],\n",
    "                    \"QuestionText\": row[\"QuestionText\"],\n",
    "                    \"AnswerText\": row[\"AnswerCText\"],\n",
    "                    \"IsCorrect\": 0,\n",
    "                    \"MisconceptionId\": row[\"MisconceptionCId\"],\n",
    "                    \"MisconceptionName\": misconception_mapping[misconception_mapping[\"MisconceptionId\"] == int(row[\"MisconceptionCId\"])][\"MisconceptionName\"].values[0],\n",
    "                    \"cot_input\": cot_input,\n",
    "                    \"cot_inference\": response\n",
    "                }])\n",
    "                cot_data = pd.concat([cot_data, new_row], ignore_index=True)\n",
    "    except Exception as e:\n",
    "        # print(response)\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cot_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cot_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cot_data[\"cot_inference\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cot_data.to_parquet(\"./adv_data/cot_data_version2_4o-mini_20240923.parquet\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
